---
title: "Adapter les résultats de Harvest models of small populations of a large carnivore using Bayesian forecasting par Andrén et al. 2020 au modèle déjà existant de dynamique des populations de loups en France"
author: "Olivier Gimenez & Loïc Pages"
date: "12/01/2024"
output:
  pdf_document: default
  html_document: default
  word_document: default
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
# Introduction

L'objectif de ce code est de modéliser la dynamique de population de loup en France et de prédir l'impact de la chasse sur celle-ci.
Pour ce faire, on reprend ici le modèle de Andrén et al. 2020. Premièrement, on calcule la viabilité de la population entre les années 1995 à 2021 selon un modèle logistique. Puis on modélise le nombre optimal d'animaux à tuer pour maintenir la viabilité de la population.

## Préparatifs

On calcule la viabilité de la population selon un modèle exponentiel qui prend aussi en compte la chasse du loup.

Tout se passe en bayésien. Si vous vous embêtez, vous pouvez m'écouter pendant 7 heures introduire tout ça [par ici](https://github.com/oliviergimenez/Bayesian_Workshop). Pour ce qui nous intéresse ici, il nous faudra un package spécifique pour implémenter les méthodes MCMC.
```{r}
library(R2jags)
library(tidyverse)
```


### Les données

```{r}
harvest <- c(0,0,0,0,0,1,0,0,2,1,2,0,0,1,0,4,4,6,18,36,34,42,51,98,105,103,169)
```

Les estimations d'effectifs par CMR:
```{r}
CMR <- c(17.1,35.4,
47.7,
25.1,
62.6,
47.9,
81.7,
110.5,
102.7,
135.9,
132.6,
101.7,
130.3,
141.4,
141.5,
175.5,
210.3,
174.5,
353.6,
280.2,
376.7,
561.2,
571.9,
682.4,
645.7,
783.8,
868)
```


On met ensemble les effectifs estimés par CMR ainsi que les nombres de loups tués.
```{r}
thedata <- cbind(round(CMR), harvest)
colnames(thedata) <- c("N", "H")
thedata <- as.data.frame(thedata)
nyears <- nrow(thedata)
```



## Modèle avec les prélèvements

On suit Andrén, H., Hobbs, N. T., Aronsson, M., Brøseth, H., Chapron, G., Linnell, J. D. C., Odden, J., Persson, J., and Nilsen, E. B.. 2020. [Harvest models of small populations of a large carnivore using Bayesian forecasting](https://esajournals.onlinelibrary.wiley.com/doi/full/10.1002/eap.2063). *Ecological Applications* 30(3):02063. 10.1002/eap.2063. 

Dans leur papier, Henrik et les collègues construisent un modèle démographique structuré en classes d'âge. J'ai pas envie de me lancer dans un truc compliqué, l'idée est simplement de comprendre comment dérouler leur approche. 

On part sur un modèle exponentiel. On stipule que les effectifs $N_{t}$ à l'année $t$ sont obtenus à partir des effectifs à l'année $t-1$ auxquels on a retranché les prélèvements $H_{t-1}$, le tout multiplié par le taux de croissance annuel $\lambda$ :
$$N_{t} = \lambda (N_{t-1} - H_{t-1}).$$
Cette relation est déterministe. Pour ajouter de la variabilité démographique, on suppose que les effectifs sont distribués selon une distribution log-normale, autrement dit que les effectifs sont normalement distribués sur l'échelle log : 
$$\log(N_{t}) \sim \text{Normale}(\mu_{t}, \sigma_{\text{proc}})$$
avec $\mu_{t} = \log(N_{t}) = \log(\lambda (N_{t-1} - H_{t-1}))$ et $\sigma_{\text{proc}}$ l'erreur standard des effectifs sur l'échelle log. On aurait pu prendre une loi de Poisson à la place. La stochasticité environnementale est en général captée par le taux de croissance, mais pas ici puisqu'il est constant. C'est une hypothèse forte du modèle. Dans l'idéal, on pourrait coupler le modèle de capture-recapture, et le modèle qui décrit l'évolution des effectifs au cours du temps. 

On ajoute une couche d'observation qui capture les erreurs sur les effectifs. Si l'on note $y_t$ les effectifs observés, on suppose que ces comptages annuels sont distribués comme une loi de Poisson de moyenne les vrais effectifs $N_{t}$:
$$y_t \sim \text{Poisson}(N_t).$$

```{r}
model <- function(){
  
  # Priors
  
  sigmaProc ~ dunif(0, 10)
  tauProc <- 1/sigmaProc^2
  lambda ~ dunif(0, 5)

  N[1] ~ dgamma(1.0E-6, 1.0E-6)
    
  # Process model
  for (t in 2:(nyears)) {
    mu[t] <- lambda * (N[t-1] - harvest[t-1])
    Nproc[t] <- log(max(1, mu[t]))
    N[t] ~ dlnorm(Nproc[t], tauProc)
  }

  # Observation model
  for (t in 1:nyears) {
    y[t] ~ dpois(N[t])
  }
  
  # Projected population
  for (t in (nyears + 1):(nyears + 10)) {
    Nproc[t] <- log(max(1, (N[t-1]/N[t-2])*(N[t-1])))
    N[t] ~ dlnorm(Nproc[t], tauProc)
  }
}
```

On prépare les données. 
```{r}
bugs.data <- list(
	nyears = nrow(thedata),
	y = round(thedata$N),
	harvest = thedata$H)
```

On précise les paramètres à estimer et le nombre de chaines de MCMC (j'en prends trois ici).
```{r}
bugs.monitor <- c("lambda", "sigmaProc","N", "tauProc")
bugs.chains <- 3
bugs.inits <- function(){
	list(
	)
}
```

Allez zooh, on lance la machine!
```{r}
library(R2jags)
wolf_mod <- jags(data = bugs.data, 
                  inits = bugs.inits, 
                  parameters.to.save = bugs.monitor, 
                  model.file = model, 
                  n.chains = bugs.chains, 
													 n.thin = 10, 
													 n.iter = 100000, 
													 n.burnin = 50000)
```


Jetons un coup d'oeil aux estimations.
```{r}
print(wolf_mod, intervals = c(2.5/100, 50/100, 97.5/100))
```

```{r}
wolf_mod$BUGSoutput$sims.matrix %>%
  as_tibble() %>%
#  pivot_longer(cols = everything(),  values_to = "value", names_to = "parameter") %>%
#  filter(str_detect(parameter, "lambda")) %>%
  ggplot() + 
  aes(x = lambda) + 
  geom_density() + 
  geom_vline(xintercept = 1, lty = "dashed", color = "red") +
  labs(x = "Taux de croissance")
```

Ensuite les projections.
```{r}
wolf_mod$BUGSoutput$sims.matrix %>%
  as_tibble() %>%
  pivot_longer(cols = everything(),  values_to = "value", names_to = "parameter") %>%
  filter(str_detect(parameter, "N")) %>%
  group_by(parameter) %>%
  summarize(medianN = median(value),
            lci = quantile(value, probs = 2.5/100),
            uci = quantile(value, probs = 97.5/100)) %>%
  mutate(an = parse_number(parameter) + 1995) %>%
  arrange(an) %>%
  ggplot() + 
  geom_ribbon(aes(x = an, y = medianN, ymin = lci, ymax = uci), fill = "red", alpha = 0.3) + 
  geom_line(aes(x = an, y = medianN), lty = "dashed", color = "red") + 
#  geom_point(aes(x = an, y = medianN), color = "red") +
  geom_point(data = bugs.data %>% as_tibble, aes(x = 1995 + 1:unique(nyears), y = y)) + 
  coord_cartesian(xlim=c(1996,2025),ylim=c(0,1200))+
  labs(y = "Effectifs de loups",
       x = "Années",
       title = "Effectifs projetés", 
       subtitle = "avec effectifs observés (points noirs)")
```


## Forecasting

Le modèle décrit l'évolution des effectifs à $t+1$ en fonction des effectifs à $t$ et permet donc de projeter les effectifs en 2021 en connaissant les effectifs de 2020 la dernière année du suivi, puis ceux de 2023 en utilisant les effectifs prédits pour 2022, et ainsi de suite. A chaque étape, il y a des erreurs qui s'accumulent. L'approche bayésienne a l'avantage de permettre de faire ces prédictions en reportant les incertitudes d'une année à l'autre. C'est ce qui fait des modèles à espace d'états en bayésien un outil très utile pour faire des projections. 

Bien. Maintenant dans le modèle utilisé, la variable effectifs prélevés est supposée connue. Il s'agit d'une donnée, et par définition on ne la connait pas dans le futur. Il nous faut donc un modèle sur les effectifs prélevés, comme on en a un sur les effectifs comptés. 

Andrén et al. proposent le modèle à espace d'états suivant : 
$$H_t \sim \text{log-Normale}\left(\max(0, \log(b_0 + b_1 y_{t-1})), \sigma_q^2 \right)$$
et 
$$q_t \sim \text{Poisson}(H_t)$$
où $q_t$ est le quota observé au temps $t$ et $H_t$ l'effectif réel d'animaux prélevés. La prédiction du modèle est $H_t$ avec une erreur de processus $\sigma_q^2$.

On retrouve l'astuce utilisée par Guillaume pour forcer la moyenne de la normale à être supérieure ou égale à 0 avec le $\max(0, \log)$.

On a deux scénarios, ou bien un quota proportionnel aux effectifs comptés avec $b_0 = 0$ (modèle 1 : proportional quota setting strategy), ou bien des prélèvements qui augmentent proportionnellement, avec un quota nul en-dessous d'un seuil (modèle 2 : threshold quota setting strategy). Ce seuil $X$ se calcule en fixant $0 = b_0 + b_1 X$ soit $X = -b_0 / b_1$. J'ai pas tout bien compris encore à ce scénario. Ca deviendra plus clair en essayant d'ajuster les modèles je suppose.

```{r}
ggplot() + 
  geom_point(aes(x = CMR, y = harvest), color = "black")  +
  expand_limits(x = 0, y = 0) +
  labs(x = "Number of wolves (year t - 1)",
       y = "Wolf quota (year t)")

```

### Modèle 1

Commençons par le modèle 1.

```{r}
model1 <- function(){
  
  # Priors
  sigmaProc ~ dunif(0, 4)
  tauProc <- 1/sigmaProc^2
  b[1] ~ dnorm(0, 3)

  # Process model
  for (t in 1:(nyears)) {
    mu[t] <- log(b[1] * y[t])
    Hproc[t] <- max(0, mu[t])
    H[t] ~ dlnorm(Hproc[t], tauProc)
    }

  # Observation model
  for (t in 1:nyears) {
    q[t] ~ dpois(H[t])
  }
  
}
```

On prépare les données.
```{r}
bugs.data <- list(
	nyears = 27,
	y = CMR,
	q = harvest)
```

On précise les paramètres à estimer et le nombre de chaines de MCMC (j'en prends trois ici).
```{r}
bugs.monitor <- c("b", "sigmaProc","H")
bugs.chains <- 3
bugs.inits <- function(){
	list(
	)
}
```

Allez zooh, on lance la machine!
```{r}
mod1 <- jags(data = bugs.data, 
                  inits = bugs.inits, 
                  parameters.to.save = bugs.monitor, 
                  model.file = model1, 
                  n.chains = bugs.chains, 
													 n.thin = 10, 
													 n.iter = 100000, 
													 n.burnin = 50000)
```


Jetons un coup d'oeil aux estimations.
```{r}
print(mod1, intervals = c(2.5/100, 50/100, 97.5/100))
```
Le paramètre $b_1$ est estimé être :
```{r}
mod1$BUGSoutput$mean$b
```


Graphiquement, on obtient. 
```{r}
grid <- seq(0, 900, length.out = length(CMR))

ggplot() + 
  geom_point(aes(x = CMR, y = harvest), color = "black") +
  geom_line(aes(x = grid, y = mod1$BUGSoutput$mean$b * grid), color = "black", lty = "dashed") + 
  
  expand_limits(x = 0, y = 0) +
  labs(x = "Number wolves (year t - 1)",
       y = "Wolf quota (year t)")
```



### Modèle 2

On écrit le modèle. La différence avec le modèe 1 est qu'on estime une ordonnée à l'origine.
```{r}
model2 <- function(){
  
  # Priors
  sigmaProc ~ dunif(0, 4)
  tauProc <- 1/sigmaProc^2
  b[1] ~ dnorm(0, 1/3000)
  b[2] ~ dnorm(0, 1/3000)
  # Process model
  for (t in 1:(nyears)) {
    mu[t] <- log(b[1] + b[2] * y[t])
#    mu[t] <- log(b[1] + b[2] * y[t]) * index[t]
#    index[t] <- - 1000 * step(y[t] + b[1] / b[2]) # step(x) = 1 if x >= 0
#    index[t] <- step(q[t]) # step(x) = 1 if x >= 0
#    mu[t] <- log(b[1] + b[2] * y[t])
    Hproc[t] <- max(0, mu[t])
    H[t] ~ dlnorm(Hproc[t], tauProc)
    
# les lignes de code suivantes donnent un ajustement pas mal, mais 
# sauf qu'à l'approche de census == 0 on a harvest == 0
#    Hproc[t] <- log(b[1] + b[2] * y[t])
#    H[t] ~ dlnorm(Hproc[t], tauProc)
    }

  # Observation model
  for (t in 1:nyears) {
    q[t] ~ dpois(H[t])
  }
  
}
```


On prépare les données pour la Suède.
```{r}
bugs.data <- list(
	nyears = 27,
	y = CMR,
	q = harvest)
```

On précise les paramètres à estimer et le nombre de chaines de MCMC (j'en prends trois ici).
```{r}
bugs.monitor <- c("b", "sigmaProc")
bugs.chains <- 3
bugs.inits <- function(){
	list(
	)
}
```

Allez zooh, on lance la machine!
```{r}
mod2 <- jags(data = bugs.data, 
                  inits = bugs.inits, 
                  parameters.to.save = bugs.monitor, 
                  model.file = model2, 
                  n.chains = bugs.chains, 
													 n.thin = 10, 
													 n.iter = 100000, 
													 n.burnin = 50000)
```


Jetons un coup d'oeil aux estimations.
```{r}
print(mod2, intervals = c(2.5/100, 50/100, 97.5/100))
```

Les paramètres $b$ sont estimés comme suit. 
```{r}
mod2$BUGSoutput$mean$b
```

Le ratio se calcule comme suit.
```{r}
- mod2$BUGSoutput$mean$b[1] / mod2$BUGSoutput$mean$b[2]
```


Graphiquement, on obtient. 
```{r}
grid <- seq(0, 900, length.out = length(CMR))
treshold = - mod2$BUGSoutput$mean$b[1] / mod2$BUGSoutput$mean$b[2]
ggplot() + 
  geom_point(aes(x = CMR, y = harvest), color = "black") +
  geom_line(aes(x = grid, y = mod1$BUGSoutput$mean$b * grid), color = "black", lty = "dashed") + 
  geom_line(aes(x = grid, y = if_else(grid < treshold, 0, (mod2$BUGSoutput$mean$b[1] +  mod2$BUGSoutput$mean$b[2] * grid))), color = "black") + 
  expand_limits(x = 0, y = 0) +
  labs(x = "Number of wolves (year t - 1)",
       y = "Wolf quota (year t)")
```

### Conclusion

On constate que le meilleur scénario pour déterminer le quota du nombre de loups à tuer est le modèle à seuil (ici à 149). 


Exemple de nombre de loup à tuer pour une population de 868 individus.
```{r}
HWolf=function(n){
  if (n>149){
  return(as.integer(-24+0.1618981*n))}
  else {return(0)}}


HWolf(868)
```


# Amélioration de la projection

A l'aide de l'estimation du nombre de loups à tuer selon la taille de la population, on modélise la projection des effecitfs en tenant compte des prélèvements.

```{r}
modelh <- function(){
  
  # Priors
  
  sigmaProc ~ dunif(0, 10)
  tauProc <- 1/sigmaProc^2
  lambda ~ dunif(0, 5)

  N[1] ~ dgamma(1.0E-6, 1.0E-6)
    
  # Process model
  for (t in 2:(nyears)) {
    mu[t] <- lambda * (N[t-1] - harvest[t-1])
    Nproc[t] <- log(max(1, mu[t]))
    N[t] ~ dlnorm(Nproc[t], tauProc)
  }

  # Observation model
  for (t in 1:nyears) {
    y[t] ~ dpois(N[t])
  }
  
  # Projected population
  for (t in (nyears + 1):(nyears + 10)) {
    mu[t] <- lambda * (N[t-1] - (-24+0.1618981*N[t-1]))
    Nproc[t] <- log(max(1, mu[t]))
    N[t] ~ dlnorm(Nproc[t], tauProc)
  }
}
```



On prépare les données. 
```{r}
bugs.data <- list(
	nyears = nrow(thedata),
	y = round(thedata$N),
	harvest = thedata$H)
```

On précise les paramètres à estimer et le nombre de chaines de MCMC (j'en prends trois ici).
```{r}
bugs.monitor <- c("lambda", "sigmaProc","N", "tauProc")
bugs.chains <- 3
bugs.inits <- function(){
	list(
	)
}
```

Allez zooh, on lance la machine!
```{r}
library(R2jags)
wolf_modh <- jags(data = bugs.data, 
                  inits = bugs.inits, 
                  parameters.to.save = bugs.monitor, 
                  model.file = modelh, 
                  n.chains = bugs.chains, 
													 n.thin = 10, 
													 n.iter = 100000, 
													 n.burnin = 50000)
```

Ensuite les projections.
```{r}
wolf_modh$BUGSoutput$sims.matrix %>%
  as_tibble() %>%
  pivot_longer(cols = everything(),  values_to = "value", names_to = "parameter") %>%
  filter(str_detect(parameter, "N")) %>%
  group_by(parameter) %>%
  summarize(medianNh = median(value),
            lci = quantile(value, probs = 2.5/100),
            uci = quantile(value, probs = 97.5/100)) %>%
  mutate(an = parse_number(parameter) + 1995) %>%
  arrange(an) %>%
  ggplot() + 
  geom_ribbon(aes(x = an, y = medianNh, ymin = lci, ymax = uci), fill = "red", alpha = 0.3) + 
  geom_line(aes(x = an, y = medianNh), lty = "dashed", color = "red") + 
#  geom_point(aes(x = an, y = medianN), color = "red") +
  geom_point(data = bugs.data %>% as_tibble, aes(x = 1995 + 1:unique(nyears), y = y)) + 
  coord_cartesian(xlim=c(1996,2023),ylim=c(0,1000))+
  labs(y = "Effectifs de loups",
       x = "Années",
       title = "Effectifs projetés", 
       subtitle = "avec effectifs observés (points noirs)")
```
